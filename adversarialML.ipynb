{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import foolbox as fb\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = tf.keras.models.load_model('mnist_cnn_model.keras')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "# MNIST data\n",
    "(x_train, y_train), (x_test, y_test) = tf.keras.datasets.mnist.load_data()\n",
    "\n",
    "# normalizing\n",
    "x_test = x_test.astype(np.float32) / 255.0\n",
    "x_test = np.expand_dims(x_test, axis=-1) \n",
    "\n",
    "# getting a subset for experimenting, first 10 images\n",
    "images = x_test[:10]  \n",
    "labels = y_test[:10]  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TensorFlow version: 2.16.1\n",
      "Foolbox version: 3.3.4\n"
     ]
    }
   ],
   "source": [
    "tf.config.run_functions_eagerly(True)\n",
    "\n",
    "print(\"TensorFlow version:\", tf.__version__)\n",
    "print(\"Foolbox version:\", fb.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "# wrapping the model with foolbox\n",
    "fmodel = fb.TensorFlowModel(model, bounds=(0, 1), preprocessing=None)\n",
    "\n",
    "def custom_loss_fn(logits, labels):\n",
    "    return tf.keras.losses.sparse_categorical_crossentropy(labels, logits, from_logits=True)\n",
    "\n",
    "# Set the custom loss function for the Foolbox attacks\n",
    "fmodel.loss_fn = custom_loss_fn\n",
    "\n",
    "# trying all the norms\n",
    "l0_attack = fb.attacks.L0FMNAttack()\n",
    "l1_attack = fb.attacks.L1FMNAttack()\n",
    "l2_attack = fb.attacks.L2FMNAttack()\n",
    "linf_attack = fb.attacks.LInfFMNAttack()\n",
    "\n",
    "# set of epsilons (perturbation levels)\n",
    "epsilons = [0.1, 0.2, 0.3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "ename": "NotImplementedError",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNotImplementedError\u001b[0m                       Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[33], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;66;03m# L0 attack\u001b[39;00m\n\u001b[0;32m----> 2\u001b[0m l0_raw_advs, l0_clipped_advs, l0_success \u001b[38;5;241m=\u001b[39m l0_attack(fmodel, images, labels, epsilons\u001b[38;5;241m=\u001b[39mepsilons)\n\u001b[1;32m      4\u001b[0m \u001b[38;5;66;03m# L1 attack\u001b[39;00m\n\u001b[1;32m      5\u001b[0m l1_raw_advs, l1_clipped_advs, l1_success \u001b[38;5;241m=\u001b[39m l1_attack(fmodel, images, labels, epsilons\u001b[38;5;241m=\u001b[39mepsilons)\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/foolbox/attacks/base.py:416\u001b[0m, in \u001b[0;36mMinimizationAttack.__call__\u001b[0;34m(***failed resolving arguments***)\u001b[0m\n\u001b[1;32m    413\u001b[0m     early_stop \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mmin\u001b[39m(epsilons)  \u001b[38;5;66;03m# type: ignore\u001b[39;00m\n\u001b[1;32m    415\u001b[0m \u001b[38;5;66;03m# run the actual attack\u001b[39;00m\n\u001b[0;32m--> 416\u001b[0m xp \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mrun(model, x, criterion, early_stop\u001b[38;5;241m=\u001b[39mearly_stop, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[1;32m    418\u001b[0m xpcs \u001b[38;5;241m=\u001b[39m []\n\u001b[1;32m    419\u001b[0m success \u001b[38;5;241m=\u001b[39m []\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/foolbox/attacks/fast_minimum_norm.py:187\u001b[0m, in \u001b[0;36mFMNAttackLp.run\u001b[0;34m(***failed resolving arguments***)\u001b[0m\n\u001b[1;32m    185\u001b[0m min_, max_ \u001b[38;5;241m=\u001b[39m model\u001b[38;5;241m.\u001b[39mbounds\n\u001b[1;32m    186\u001b[0m rows \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mrange\u001b[39m(N)\n\u001b[0;32m--> 187\u001b[0m grad_and_logits \u001b[38;5;241m=\u001b[39m ep\u001b[38;5;241m.\u001b[39mvalue_and_grad_fn(x, loss_fn, has_aux\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[1;32m    189\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mp \u001b[38;5;241m!=\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[1;32m    190\u001b[0m     epsilon \u001b[38;5;241m=\u001b[39m ep\u001b[38;5;241m.\u001b[39minf \u001b[38;5;241m*\u001b[39m ep\u001b[38;5;241m.\u001b[39mones(x, \u001b[38;5;28mlen\u001b[39m(x))\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/eagerpy/framework.py:354\u001b[0m, in \u001b[0;36mvalue_and_grad_fn\u001b[0;34m(t, f, has_aux)\u001b[0m\n\u001b[1;32m    353\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mvalue_and_grad_fn\u001b[39m(t: Any, f: Any, has_aux: \u001b[38;5;28mbool\u001b[39m \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Any:\n\u001b[0;32m--> 354\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m t\u001b[38;5;241m.\u001b[39m_value_and_grad_fn(f, has_aux\u001b[38;5;241m=\u001b[39mhas_aux)\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/eagerpy/tensor/numpy.py:383\u001b[0m, in \u001b[0;36mNumPyTensor._value_and_grad_fn\u001b[0;34m(self, f, has_aux)\u001b[0m\n\u001b[1;32m    379\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_value_and_grad_fn\u001b[39m(  \u001b[38;5;66;03m# noqa: F811 (waiting for pyflakes > 2.1.1)\u001b[39;00m\n\u001b[1;32m    380\u001b[0m     \u001b[38;5;28mself\u001b[39m: TensorType, f: Callable, has_aux: \u001b[38;5;28mbool\u001b[39m \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m\n\u001b[1;32m    381\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Callable[\u001b[38;5;241m.\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;241m.\u001b[39m, Tuple]:\n\u001b[1;32m    382\u001b[0m     \u001b[38;5;66;03m# TODO: maybe implement this using https://github.com/HIPS/autograd\u001b[39;00m\n\u001b[0;32m--> 383\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mNotImplementedError\u001b[39;00m\n",
      "\u001b[0;31mNotImplementedError\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# L0 attack\n",
    "l0_raw_advs, l0_clipped_advs, l0_success = l0_attack(fmodel, images, labels, epsilons=epsilons)\n",
    "\n",
    "# L1 attack\n",
    "l1_raw_advs, l1_clipped_advs, l1_success = l1_attack(fmodel, images, labels, epsilons=epsilons)\n",
    "\n",
    "# L2 attack\n",
    "l2_raw_advs, l2_clipped_advs, l2_success = l2_attack(fmodel, images, labels, epsilons=epsilons)\n",
    "\n",
    "# Linf attack\n",
    "linf_raw_advs, linf_clipped_advs, linf_success = linf_attack(fmodel, images, labels, epsilons=epsilons)\n",
    "\n",
    "# shows which images where successfully attacked\n",
    "print(\"L0 attack success:\", l0_success)\n",
    "print(\"L1 attack success:\", l1_success)\n",
    "print(\"L2 attack success:\", l2_success)\n",
    "print(\"Linf attack success:\", linf_success)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_comparison(images, adv_images, adv_labels, norm_name):\n",
    "    fig, axes = plt.subplots(2, 10, figsize=(20, 4))\n",
    "    for i in range(10):\n",
    "        # original image\n",
    "        axes[0, i].imshow(images[i].squeeze(), cmap=\"gray\")\n",
    "        axes[0, i].set_title(f\"Original: {labels[i]}\")\n",
    "        axes[0, i].axis('off')\n",
    "\n",
    "        # adversarial image\n",
    "        axes[1, i].imshow(adv_images[i].squeeze(), cmap=\"gray\")\n",
    "        axes[1, i].set_title(f\"Adv: {adv_labels[i]}\")\n",
    "        axes[1, i].axis('off')\n",
    "\n",
    "    plt.suptitle(f\"Adversarial examples with {norm_name} norm\", fontsize=16)\n",
    "    plt.show()\n",
    "\n",
    "# everywhere for epsilon = 0.2\n",
    "\n",
    "# L0 attack results\n",
    "l0_adv_labels = np.argmax(fmodel(l0_clipped_advs[1]), axis=-1)  \n",
    "plot_comparison(images, l0_clipped_advs[1], l0_adv_labels, \"L0\")\n",
    "\n",
    "# L1 attack results\n",
    "l1_adv_labels = np.argmax(fmodel(l1_clipped_advs[1]), axis=-1)  \n",
    "plot_comparison(images, l1_clipped_advs[1], l1_adv_labels, \"L1\")\n",
    "\n",
    "# L2 attack results\n",
    "l2_adv_labels = np.argmax(fmodel(l2_clipped_advs[1]), axis=-1)  \n",
    "plot_comparison(images, l2_clipped_advs[1], l2_adv_labels, \"L2\")\n",
    "\n",
    "# Linf attack results\n",
    "linf_adv_labels = np.argmax(fmodel(linf_clipped_advs[1]), axis=-1) \n",
    "plot_comparison(images, linf_clipped_advs[1], linf_adv_labels, \"Linf\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# success rate for each attack\n",
    "l0_success_rate = np.mean(l0_success)\n",
    "l1_success_rate = np.mean(l1_success)\n",
    "l2_success_rate = np.mean(l2_success)\n",
    "linf_success_rate = np.mean(linf_success)\n",
    "\n",
    "print(f\"L0 Success Rate: {l0_success_rate * 100:.2f}%\")\n",
    "print(f\"L1 Success Rate: {l1_success_rate * 100:.2f}%\")\n",
    "print(f\"L2 Success Rate: {l2_success_rate * 100:.2f}%\")\n",
    "print(f\"Linf Success Rate: {linf_success_rate * 100:.2f}%\")"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
